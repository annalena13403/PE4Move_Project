{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PE4MOVE Data Preparation Pipeline\n",
    "\n",
    "This notebook prepares the PE4MOVE dataset for machine learning analysis by:\n",
    "1. Loading and exploring the raw data\n",
    "2. Identifying intervention and control groups\n",
    "3. Filtering participants with complete T1 (follow-up) data\n",
    "4. Creating derived variables (motivation, self-monitoring)\n",
    "5. Cleaning and selecting relevant attributes\n",
    "6. Exporting separate CSV files for intervention and control groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Dataset\n",
    "\n",
    "Load the PE4MOVE dataset and display basic information about its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (3193, 381)\n",
      "Participants: 3,193\n",
      "Variables: 381\n",
      "\n",
      "First few columns: ['Age', 'Sex', 'MVPA_Frequency_T0', 'MVPA_d0', 'MVPA_d1', 'MVPA_d2', 'MVPA_d3', 'MVPA_d4', 'MVPA_d5', 'MVPA_d6']\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('data/PE4MOVE_6MWT.csv')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Participants: {len(df):,}\")\n",
    "print(f\"Variables: {df.shape[1]}\")\n",
    "print(f\"\\nFirst few columns: {df.columns[:10].tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Identify Intervention and Control Groups\n",
    "\n",
    "The dataset contains a `Group_Final` variable that indicates whether each participant was in Group A or Group B. We need to determine which group received the intervention by examining changes in MVPA (Moderate-to-Vigorous Physical Activity) frequency from T0 (baseline) to T1 (follow-up)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group Distribution:\n",
      "Group_Final\n",
      "A    2095\n",
      "B    1098\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Missing group assignments: 0\n",
      "\n",
      "Group A (n=1007 paired):\n",
      "  MVPA_Frequency_T0: 3.20\n",
      "  MVPA_Frequency_T1: 3.49\n",
      "  Change: +0.29 (+8.9%)\n",
      "\n",
      "Group B (n=763 paired):\n",
      "  MVPA_Frequency_T0: 3.05\n",
      "  MVPA_Frequency_T1: 3.26\n",
      "  Change: +0.21 (+6.9%)\n",
      "\n",
      "======================================================================\n",
      "CONCLUSION: Group A → INTERVENTION GROUP\n",
      "            Group B → CONTROL GROUP\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Check group distribution\n",
    "print(\"Group Distribution:\")\n",
    "print(df['Group_Final'].value_counts())\n",
    "print(f\"\\nMissing group assignments: {df['Group_Final'].isna().sum()}\")\n",
    "\n",
    "# Compare MVPA changes between groups to identify intervention group\n",
    "for group in ['A', 'B']:\n",
    "    group_data = df[df['Group_Final'] == group]\n",
    "    \n",
    "    # Use only paired data (participants with both T0 and T1)\n",
    "    paired_mask = group_data['MVPA_Frequency_T0'].notna() & group_data['MVPA_Frequency_T1'].notna()\n",
    "    paired_data = group_data[paired_mask]\n",
    "    \n",
    "    t0_mean = paired_data['MVPA_Frequency_T0'].mean()\n",
    "    t1_mean = paired_data['MVPA_Frequency_T1'].mean()\n",
    "    change = t1_mean - t0_mean\n",
    "    change_pct = (change / t0_mean * 100) if t0_mean > 0 else 0\n",
    "    \n",
    "    print(f\"\\nGroup {group} (n={paired_mask.sum()} paired):\")\n",
    "    print(f\"  MVPA_Frequency_T0: {t0_mean:.2f}\")\n",
    "    print(f\"  MVPA_Frequency_T1: {t1_mean:.2f}\")\n",
    "    print(f\"  Change: {change:+.2f} ({change_pct:+.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CONCLUSION: Group A → INTERVENTION GROUP\")\n",
    "print(\"            Group B → CONTROL GROUP\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Split Dataset into Intervention and Control Groups\n",
    "\n",
    "Based on the analysis above, we split the dataset into:\n",
    "- **Intervention group** (Group A): Received the PE4MOVE program\n",
    "- **Control group** (Group B): Did not receive the intervention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intervention group (Group A): 2095 participants\n",
      "Control group (Group B): 1098 participants\n"
     ]
    }
   ],
   "source": [
    "# Split into intervention and control groups\n",
    "df_intervention = df[df['Group_Final'] == 'A'].copy()\n",
    "df_control = df[df['Group_Final'] == 'B'].copy()\n",
    "\n",
    "print(f\"Intervention group (Group A): {len(df_intervention)} participants\")\n",
    "print(f\"Control group (Group B): {len(df_control)} participants\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Filter Participants with Complete T1 Data\n",
    "\n",
    "For our analysis, we only include participants who have complete follow-up (T1) data for MVPA frequency. This ensures we can measure the outcome of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTERVENTION GROUP:\n",
      "  Original: 2095 participants\n",
      "  Missing MVPA_Frequency_T1: 1088\n",
      "  After filtering: 1007 participants\n",
      "  Retention rate: 48.1%\n",
      "\n",
      "CONTROL GROUP:\n",
      "  Original: 1098 participants\n",
      "  Missing MVPA_Frequency_T1: 335\n",
      "  After filtering: 763 participants\n",
      "  Retention rate: 69.5%\n"
     ]
    }
   ],
   "source": [
    "# Filter intervention group for complete T1 data\n",
    "print(\"INTERVENTION GROUP:\")\n",
    "print(f\"  Original: {len(df_intervention)} participants\")\n",
    "print(f\"  Missing MVPA_Frequency_T1: {df_intervention['MVPA_Frequency_T1'].isna().sum()}\")\n",
    "\n",
    "df_intervention_clean = df_intervention[df_intervention['MVPA_Frequency_T1'].notna()].copy()\n",
    "print(f\"  After filtering: {len(df_intervention_clean)} participants\")\n",
    "print(f\"  Retention rate: {len(df_intervention_clean)/len(df_intervention)*100:.1f}%\")\n",
    "\n",
    "# Filter control group for complete T1 data\n",
    "print(\"\\nCONTROL GROUP:\")\n",
    "print(f\"  Original: {len(df_control)} participants\")\n",
    "print(f\"  Missing MVPA_Frequency_T1: {df_control['MVPA_Frequency_T1'].isna().sum()}\")\n",
    "\n",
    "df_control_clean = df_control[df_control['MVPA_Frequency_T1'].notna()].copy()\n",
    "print(f\"  After filtering: {len(df_control_clean)} participants\")\n",
    "print(f\"  Retention rate: {len(df_control_clean)/len(df_control)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create Derived Variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Remove \"Prefer not to say\" Values\n",
    "\n",
    "Before calculating, we need to replace values (\"prefer not to say\") with NaN in score-based columns. This ensures that these values are excluded from all calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTERVENTION GROUP:\n",
      "Cleaned 'prefer not to say' values:\n",
      "  Value 6: 4112 occurrences replaced with NaN\n",
      "  Value 8: 65 occurrences replaced with NaN\n",
      "  Value 11: 121 occurrences replaced with NaN\n",
      "  Total: 4298 values replaced with NaN\n",
      "\n",
      "CONTROL GROUP:\n",
      "Cleaned 'prefer not to say' values:\n",
      "  Value 6: 2479 occurrences replaced with NaN\n",
      "  Value 8: 48 occurrences replaced with NaN\n",
      "  Value 11: 67 occurrences replaced with NaN\n",
      "  Total: 2594 values replaced with NaN\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def clean_prefer_not_to_say_values(df):\n",
    "    \"\"\"\n",
    "    Replace 'prefer not to say' values with NaN for all relevant columns.\n",
    "    Different columns use different numeric codes for this response.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the mapping of columns to their \"prefer not to say\" values\n",
    "    prefer_not_to_say_mapping = {\n",
    "        # Value = 3\n",
    "        'Sex': 3,\n",
    "        \n",
    "        # Value = 6\n",
    "        'Leisure_Exercise_T0': 6,\n",
    "        'Leisure_Exercise_T1': 6,\n",
    "        'YAP_sedentary_general_T0': 6,\n",
    "        'YAP_sedentary_general_T1': 6,\n",
    "        'Leisure_PA_T0': 6,\n",
    "        'Leisure_PA_T1': 6,\n",
    "        'PE_hours_T0': 6,\n",
    "        'PE_hours_T1': 6,\n",
    "        'Extracurricular_Session_Coach_T0': 6,\n",
    "        'Extracurricular_Session_Coach_T1': 6,\n",
    "        'Extracurricular_Session_School_T0': 6,\n",
    "        'Extracurricular_Session_School_T1': 6,\n",
    "        \n",
    "        # Value = 8\n",
    "        'MVPA_Frequency_T0': 8,\n",
    "        'MVPA_Frequency_T1': 8,\n",
    "        'MVPA_Usual_Week_T0': 8,\n",
    "        'MVPA_Usual_Week_T1': 8,\n",
    "        \n",
    "        # Value = 11\n",
    "        'COVID_impact_T0': 11,\n",
    "        'COVID_impact_T1': 11,\n",
    "    }\n",
    "    \n",
    "    # Add all Self_Monitoring columns (value = 6)\n",
    "    for i in range(1, 5):\n",
    "        prefer_not_to_say_mapping[f'Self_Monitoring_{i}_T0'] = 6\n",
    "        prefer_not_to_say_mapping[f'Self_Monitoring_{i}_T1'] = 6\n",
    "    \n",
    "    # Add all Motivation-related columns (value = 6)\n",
    "    motiv_types = ['Instrinsic', 'Identified', 'Extrinsic', 'Introjected']\n",
    "    for motiv_type in motiv_types:\n",
    "        for i in range(1, 5):\n",
    "            prefer_not_to_say_mapping[f'Motiv_{motiv_type}_{i}_T0'] = 6\n",
    "            prefer_not_to_say_mapping[f'Motiv_{motiv_type}_{i}_T1'] = 6\n",
    "    \n",
    "    # Add all Amotivation columns (value = 6)\n",
    "    for i in range(1, 5):\n",
    "        prefer_not_to_say_mapping[f'Amotivation_{i}_T0'] = 6\n",
    "        prefer_not_to_say_mapping[f'Amotivation_{i}_T1'] = 6\n",
    "    \n",
    "    # Replace the values\n",
    "    total_replaced = 0\n",
    "    replacements_by_value = {}\n",
    "    \n",
    "    for col, pref_value in prefer_not_to_say_mapping.items():\n",
    "        if col in df.columns:\n",
    "            count = (df[col] == pref_value).sum()\n",
    "            if count > 0:\n",
    "                df[col] = df[col].replace(pref_value, np.nan)\n",
    "                total_replaced += count\n",
    "                if pref_value not in replacements_by_value:\n",
    "                    replacements_by_value[pref_value] = 0\n",
    "                replacements_by_value[pref_value] += count\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"Cleaned 'prefer not to say' values:\")\n",
    "    for value, count in sorted(replacements_by_value.items()):\n",
    "        print(f\"  Value {value}: {count} occurrences replaced with NaN\")\n",
    "    print(f\"  Total: {total_replaced} values replaced with NaN\\n\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Clean both datasets\n",
    "print(\"INTERVENTION GROUP:\")\n",
    "df_intervention_clean = clean_prefer_not_to_say_values(df_intervention_clean)\n",
    "\n",
    "print(\"CONTROL GROUP:\")\n",
    "df_control_clean = clean_prefer_not_to_say_values(df_control_clean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Motivation Scores\n",
    "\n",
    "We create overall motivation scores based on Self-Determination Theory:\n",
    "- **Formula**: `((Intrinsic + Identified) / 2) - ((Extrinsic + Introjected + Amotivation) / 3)`\n",
    "- Higher scores indicate more autonomous (self-determined) motivation\n",
    "- Created for both T0 (baseline) and T1 (follow-up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTERVENTION GROUP:\n",
      "Created Motivation_T0: mean=7.08, std=4.60\n",
      "Created Motivation_T1: mean=6.18, std=5.20\n",
      "\n",
      "CONTROL GROUP:\n",
      "Created Motivation_T0: mean=6.80, std=4.61\n",
      "Created Motivation_T1: mean=6.19, std=5.33\n"
     ]
    }
   ],
   "source": [
    "def create_motivation_scores(df):\n",
    "    \"\"\"Create overall motivation scores from individual components.\"\"\"\n",
    "    \n",
    "    # Motivation_T0\n",
    "    df['Motivation_T0'] = (\n",
    "        (df['Motiv_Instrinsic_1_T0'] + df['Motiv_Instrinsic_2_T0'] + \n",
    "         df['Motiv_Instrinsic_3_T0'] + df['Motiv_Instrinsic_4_T0'] +\n",
    "         df['Motiv_Identified_1_T0'] + df['Motiv_Identified_2_T0'] + \n",
    "         df['Motiv_Identified_3_T0'] + df['Motiv_Identified_4_T0']) / 2 -\n",
    "        (df['Motiv_Extrinsic_1_T0'] + df['Motiv_Extrinsic_2_T0'] + \n",
    "         df['Motiv_Extrinsic_3_T0'] + df['Motiv_Extrinsic_4_T0'] +\n",
    "         df['Motiv_Introjected_1_T0'] + df['Motiv_Introjected_2_T0'] + \n",
    "         df['Motiv_Introjected_3_T0'] + df['Motiv_Introjected_4_T0'] +\n",
    "         df['Amotivation_1_T0'] + df['Amotivation_2_T0'] + \n",
    "         df['Amotivation_3_T0'] + df['Amotivation_4_T0']) / 3\n",
    "    )\n",
    "    \n",
    "    # Motivation_T1\n",
    "    df['Motivation_T1'] = (\n",
    "        (df['Motiv_Instrinsic_1_T1'] + df['Motiv_Instrinsic_2_T1'] + \n",
    "         df['Motiv_Instrinsic_3_T1'] + df['Motiv_Instrinsic_4_T1'] +\n",
    "         df['Motiv_Identified_1_T1'] + df['Motiv_Identified_2_T1'] + \n",
    "         df['Motiv_Identified_3_T1'] + df['Motiv_Identified_4_T1']) / 2 -\n",
    "        (df['Motiv_Extrinsic_1_T1'] + df['Motiv_Extrinsic_2_T1'] + \n",
    "         df['Motiv_Extrinsic_3_T1'] + df['Motiv_Extrinsic_4_T1'] +\n",
    "         df['Motiv_Introjected_1_T1'] + df['Motiv_Introjected_2_T1'] + \n",
    "         df['Motiv_Introjected_3_T1'] + df['Motiv_Introjected_4_T1'] +\n",
    "         df['Amotivation_1_T1'] + df['Amotivation_2_T1'] + \n",
    "         df['Amotivation_3_T1'] + df['Amotivation_4_T1']) / 3\n",
    "    )\n",
    "    \n",
    "    print(f\"Created Motivation_T0: mean={df['Motivation_T0'].mean():.2f}, std={df['Motivation_T0'].std():.2f}\")\n",
    "    print(f\"Created Motivation_T1: mean={df['Motivation_T1'].mean():.2f}, std={df['Motivation_T1'].std():.2f}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Create motivation scores for both groups\n",
    "print(\"INTERVENTION GROUP:\")\n",
    "df_intervention_clean = create_motivation_scores(df_intervention_clean)\n",
    "\n",
    "print(\"\\nCONTROL GROUP:\")\n",
    "df_control_clean = create_motivation_scores(df_control_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Self-Monitoring Scores\n",
    "\n",
    "We create overall self-monitoring scores by averaging the 4 individual self-monitoring items for both T0 and T1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTERVENTION GROUP:\n",
      "Created Self_Monitoring_T0: mean=3.29, std=1.21\n",
      "Created Self_Monitoring_T1: mean=3.35, std=1.17\n",
      "\n",
      "CONTROL GROUP:\n",
      "Created Self_Monitoring_T0: mean=3.17, std=1.23\n",
      "Created Self_Monitoring_T1: mean=3.30, std=1.21\n"
     ]
    }
   ],
   "source": [
    "def create_self_monitoring_scores(df):\n",
    "    \"\"\"Create overall self-monitoring scores from individual items.\"\"\"\n",
    "    \n",
    "    # Self_Monitoring_T0: average of the 4 T0 items\n",
    "    df['Self_Monitoring_T0'] = (\n",
    "        df['Self_Monitoring_1_T0'] + df['Self_Monitoring_2_T0'] + \n",
    "        df['Self_Monitoring_3_T0'] + df['Self_Monitoring_4_T0']\n",
    "    ) / 4\n",
    "    \n",
    "    # Self_Monitoring_T1: average of the 4 T1 items\n",
    "    df['Self_Monitoring_T1'] = (\n",
    "        df['Self_Monitoring_1_T1'] + df['Self_Monitoring_2_T1'] + \n",
    "        df['Self_Monitoring_3_T1'] + df['Self_Monitoring_4_T1']\n",
    "    ) / 4\n",
    "    \n",
    "    print(f\"Created Self_Monitoring_T0: mean={df['Self_Monitoring_T0'].mean():.2f}, std={df['Self_Monitoring_T0'].std():.2f}\")\n",
    "    print(f\"Created Self_Monitoring_T1: mean={df['Self_Monitoring_T1'].mean():.2f}, std={df['Self_Monitoring_T1'].std():.2f}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Create self-monitoring scores for both groups\n",
    "print(\"INTERVENTION GROUP:\")\n",
    "df_intervention_clean = create_self_monitoring_scores(df_intervention_clean)\n",
    "\n",
    "print(\"\\nCONTROL GROUP:\")\n",
    "df_control_clean = create_self_monitoring_scores(df_control_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 MVPA_Improvement Scores\n",
    "\n",
    "Now we calculate MVPA improvement scores by finding the difference in MVPA frequency from T0 to T1. This calculation happens after cleaning \"prefer not to say\" values, so those responses are properly excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTERVENTION GROUP:\n",
      "  Valid calculations: 971 participants\n",
      "  Missing (due to NaN in T0 or T1): 36 participants\n",
      "  Mean change: 0.31\n",
      "  Std deviation: 1.71\n",
      "\n",
      "  Participants improved: 407 (41.9%)\n",
      "  Participants declined: 263 (27.1%)\n",
      "  Participants unchanged: 301 (31.0%)\n",
      "\n",
      "CONTROL GROUP:\n",
      "  Valid calculations: 741 participants\n",
      "  Missing (due to NaN in T0 or T1): 22 participants\n",
      "  Mean change: 0.25\n",
      "  Std deviation: 1.80\n",
      "\n",
      "  Participants improved: 302 (40.8%)\n",
      "  Participants declined: 215 (29.0%)\n",
      "  Participants unchanged: 224 (30.2%)\n"
     ]
    }
   ],
   "source": [
    "def calculate_mvpa_improvement(df):\n",
    "\n",
    "    df['MVPA_Improvement'] = df['MVPA_Frequency_T1'] - df['MVPA_Frequency_T0']\n",
    "    \n",
    "    # Summary statistics (excluding NaN values)\n",
    "    improvement = df['MVPA_Improvement']\n",
    "    valid_improvements = improvement.dropna()\n",
    "    n_improved = (valid_improvements > 0).sum()\n",
    "    n_declined = (valid_improvements < 0).sum()\n",
    "    n_unchanged = (valid_improvements == 0).sum()\n",
    "    n_missing = improvement.isna().sum()\n",
    "    \n",
    "    print(f\"  Valid calculations: {len(valid_improvements)} participants\")\n",
    "    print(f\"  Missing (due to NaN in T0 or T1): {n_missing} participants\")\n",
    "    print(f\"  Mean change: {improvement.mean():.2f}\")\n",
    "    print(f\"  Std deviation: {improvement.std():.2f}\")\n",
    "    print(f\"\\n  Participants improved: {n_improved} ({n_improved/len(valid_improvements)*100:.1f}%)\")\n",
    "    print(f\"  Participants declined: {n_declined} ({n_declined/len(valid_improvements)*100:.1f}%)\")\n",
    "    print(f\"  Participants unchanged: {n_unchanged} ({n_unchanged/len(valid_improvements)*100:.1f}%)\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Calculate MVPA_Improvement for intervention group (AFTER cleaning value 8)\n",
    "print(\"INTERVENTION GROUP:\")\n",
    "df_intervention_clean = calculate_mvpa_improvement(df_intervention_clean)\n",
    "\n",
    "# Calculate MVPA_Improvement for control group (AFTER cleaning value 8)\n",
    "print(\"\\nCONTROL GROUP:\")\n",
    "df_control_clean = calculate_mvpa_improvement(df_control_clean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Select Final Variables\n",
    "\n",
    "Now we select only the specific variables needed for ML analysis:\n",
    "- Demographics (Age, Sex, Gender, Age_Group)\n",
    "- Physical activity measures (MVPA frequency, leisure activities, usual week)\n",
    "- Sedentary behavior (YAP_sedentary_general for T0 and T1)\n",
    "- Anthropometric data (Weight, Height, BMI)\n",
    "- Fitness tests (6-minute walk, standing long jump, handgrip strength)\n",
    "- School-related PA (PE hours, extracurricular sessions)\n",
    "- COVID impact\n",
    "- **Derived aggregate scores** (Motivation_T0, Motivation_T1, Self_Monitoring_T0, Self_Monitoring_T1)\n",
    "- Outcome measure (MVPA_Improvement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTERVENTION GROUP:\n",
      "\n",
      "Dataset shape: (1007, 386) → (1007, 38)\n",
      "Selected 38 columns out of 38 required\n",
      "\n",
      "CONTROL GROUP:\n",
      "\n",
      "Dataset shape: (763, 386) → (763, 38)\n",
      "Selected 38 columns out of 38 required\n"
     ]
    }
   ],
   "source": [
    "def clean_dataset(df):\n",
    "    \n",
    "    # Define the exact columns we want to keep (41 columns total)\n",
    "    required_columns = [\n",
    "        'Age', 'Sex', 'MVPA_Frequency_T0', 'Leisure_Exercise_T0',\n",
    "        'YAP_sedentary_general_T0', 'Leisure_PA_T0', 'MVPA_Usual_Week_T0', 'Group_Final',\n",
    "        'Weight_kg_T0', 'Weight_kg_T1', 'Height_cm_T0', 'Height_cm_T1',\n",
    "        'MVPA_Frequency_T1', 'MVPA_Usual_Week_T1', 'Leisure_Exercise_T1',\n",
    "        'PE_hours_T0', 'PE_hours_T1',\n",
    "        'Extracurricular_Session_Coach_T0', 'Extracurricular_Session_Coach_T1',\n",
    "        'Extracurricular_Session_School_T0', 'Extracurricular_Session_School_T1',\n",
    "        'Leisure_PA_T1', 'YAP_sedentary_general_T1',\n",
    "        'COVID_impact_T0', 'COVID_impact_T1',\n",
    "        'SixMW_T0', 'SixMW_T1', 'SLJ_T0', 'SLJ_T1',\n",
    "        'HG_Right_T0', 'HG_Left_T0', 'HG_Right_T1', 'HG_Left_T1','MVPA_Improvement', \n",
    "        'Motivation_T0', 'Motivation_T1',\n",
    "        'Self_Monitoring_T0', 'Self_Monitoring_T1'\n",
    "    ]\n",
    "    \n",
    "    # Check which required columns exist in the dataframe\n",
    "    available_columns = [col for col in required_columns if col in df.columns]\n",
    "    missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "    \n",
    "    if missing_columns:\n",
    "        print(f\"Warning: {len(missing_columns)} required columns not found in dataset:\")\n",
    "        for col in missing_columns:\n",
    "            print(f\"     - {col}\")\n",
    "    \n",
    "    # Select only available columns\n",
    "    df_cleaned = df[available_columns].copy()\n",
    "    \n",
    "    print(f\"\\nDataset shape: {df.shape} → {df_cleaned.shape}\")\n",
    "    print(f\"Selected {len(available_columns)} columns out of {len(required_columns)} required\")\n",
    "    \n",
    "    return df_cleaned\n",
    "\n",
    "# Clean both datasets\n",
    "print(\"INTERVENTION GROUP:\")\n",
    "df_intervention_final = clean_dataset(df_intervention_clean)\n",
    "\n",
    "print(\"\\nCONTROL GROUP:\")\n",
    "df_control_final = clean_dataset(df_control_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Final Dataset Summary\n",
    "\n",
    "Review the final cleaned datasets before export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "FINAL DATASET SUMMARY\n",
      "======================================================================\n",
      "\n",
      "INTERVENTION GROUP:\n",
      "  Participants: 1007\n",
      "  Variables: 38\n",
      "\n",
      "CONTROL GROUP:\n",
      "  Participants: 763\n",
      "  Variables: 38\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"FINAL DATASET SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nINTERVENTION GROUP:\")\n",
    "print(f\"  Participants: {len(df_intervention_final)}\")\n",
    "print(f\"  Variables: {df_intervention_final.shape[1]}\")\n",
    "\n",
    "print(\"\\nCONTROL GROUP:\")\n",
    "print(f\"  Participants: {len(df_control_final)}\")\n",
    "print(f\"  Variables: {df_control_final.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1007 entries, 0 to 3190\n",
      "Data columns (total 38 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   Age                                1007 non-null   int64  \n",
      " 1   Sex                                1007 non-null   int64  \n",
      " 2   MVPA_Frequency_T0                  986 non-null    float64\n",
      " 3   Leisure_Exercise_T0                983 non-null    float64\n",
      " 4   YAP_sedentary_general_T0           976 non-null    float64\n",
      " 5   Leisure_PA_T0                      983 non-null    float64\n",
      " 6   MVPA_Usual_Week_T0                 992 non-null    float64\n",
      " 7   Group_Final                        1007 non-null   object \n",
      " 8   Weight_kg_T0                       1007 non-null   int64  \n",
      " 9   Weight_kg_T1                       814 non-null    float64\n",
      " 10  Height_cm_T0                       1007 non-null   int64  \n",
      " 11  Height_cm_T1                       814 non-null    float64\n",
      " 12  MVPA_Frequency_T1                  990 non-null    float64\n",
      " 13  MVPA_Usual_Week_T1                 995 non-null    float64\n",
      " 14  Leisure_Exercise_T1                987 non-null    float64\n",
      " 15  PE_hours_T0                        1003 non-null   float64\n",
      " 16  PE_hours_T1                        995 non-null    float64\n",
      " 17  Extracurricular_Session_Coach_T0   985 non-null    float64\n",
      " 18  Extracurricular_Session_Coach_T1   990 non-null    float64\n",
      " 19  Extracurricular_Session_School_T0  973 non-null    float64\n",
      " 20  Extracurricular_Session_School_T1  966 non-null    float64\n",
      " 21  Leisure_PA_T1                      986 non-null    float64\n",
      " 22  YAP_sedentary_general_T1           958 non-null    float64\n",
      " 23  COVID_impact_T0                    973 non-null    float64\n",
      " 24  COVID_impact_T1                    920 non-null    float64\n",
      " 25  SixMW_T0                           1007 non-null   int64  \n",
      " 26  SixMW_T1                           877 non-null    float64\n",
      " 27  SLJ_T0                             993 non-null    float64\n",
      " 28  SLJ_T1                             918 non-null    float64\n",
      " 29  HG_Right_T0                        983 non-null    float64\n",
      " 30  HG_Left_T0                         984 non-null    float64\n",
      " 31  HG_Right_T1                        904 non-null    float64\n",
      " 32  HG_Left_T1                         906 non-null    float64\n",
      " 33  MVPA_Improvement                   971 non-null    float64\n",
      " 34  Motivation_T0                      819 non-null    float64\n",
      " 35  Motivation_T1                      768 non-null    float64\n",
      " 36  Self_Monitoring_T0                 911 non-null    float64\n",
      " 37  Self_Monitoring_T1                 846 non-null    float64\n",
      "dtypes: float64(32), int64(5), object(1)\n",
      "memory usage: 306.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>MVPA_Frequency_T0</th>\n",
       "      <th>Leisure_Exercise_T0</th>\n",
       "      <th>YAP_sedentary_general_T0</th>\n",
       "      <th>Leisure_PA_T0</th>\n",
       "      <th>MVPA_Usual_Week_T0</th>\n",
       "      <th>Group_Final</th>\n",
       "      <th>Weight_kg_T0</th>\n",
       "      <th>Weight_kg_T1</th>\n",
       "      <th>...</th>\n",
       "      <th>SLJ_T1</th>\n",
       "      <th>HG_Right_T0</th>\n",
       "      <th>HG_Left_T0</th>\n",
       "      <th>HG_Right_T1</th>\n",
       "      <th>HG_Left_T1</th>\n",
       "      <th>MVPA_Improvement</th>\n",
       "      <th>Motivation_T0</th>\n",
       "      <th>Motivation_T1</th>\n",
       "      <th>Self_Monitoring_T0</th>\n",
       "      <th>Self_Monitoring_T1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>A</td>\n",
       "      <td>39</td>\n",
       "      <td>41.0</td>\n",
       "      <td>...</td>\n",
       "      <td>162.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.333333</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>45</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>110.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>A</td>\n",
       "      <td>54</td>\n",
       "      <td>53.0</td>\n",
       "      <td>...</td>\n",
       "      <td>143.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>A</td>\n",
       "      <td>38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>135.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.166667</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>4.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>A</td>\n",
       "      <td>44</td>\n",
       "      <td>42.0</td>\n",
       "      <td>...</td>\n",
       "      <td>153.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>12.333333</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Sex  MVPA_Frequency_T0  Leisure_Exercise_T0  \\\n",
       "0    11    2                3.0                  0.0   \n",
       "2    11    2                1.0                  1.0   \n",
       "6    11    2                2.0                  4.0   \n",
       "7    11    2                4.0                  5.0   \n",
       "12   11    1                3.0                  4.0   \n",
       "\n",
       "    YAP_sedentary_general_T0  Leisure_PA_T0  MVPA_Usual_Week_T0 Group_Final  \\\n",
       "0                        2.0            3.0                 3.0           A   \n",
       "2                        4.0            1.0                 1.0           A   \n",
       "6                        2.0            3.0                 3.0           A   \n",
       "7                        2.0            3.0                 4.0           A   \n",
       "12                       3.0            3.0                 3.0           A   \n",
       "\n",
       "    Weight_kg_T0  Weight_kg_T1  ...  SLJ_T1  HG_Right_T0  HG_Left_T0  \\\n",
       "0             39          41.0  ...   162.0         50.0        55.0   \n",
       "2             45          40.0  ...   110.0         21.0        20.0   \n",
       "6             54          53.0  ...   143.0         23.0        21.0   \n",
       "7             38           NaN  ...   135.0         18.0        20.0   \n",
       "12            44          42.0  ...   153.0         50.0        50.0   \n",
       "\n",
       "    HG_Right_T1  HG_Left_T1  MVPA_Improvement  Motivation_T0  Motivation_T1  \\\n",
       "0          60.0        60.0               0.0      12.333333      14.500000   \n",
       "2          20.0        20.0               1.0            NaN            NaN   \n",
       "6           NaN         NaN               1.0       4.000000       1.166667   \n",
       "7          22.0        20.0               0.0      13.166667       3.500000   \n",
       "12         55.0        50.0               0.0      13.500000      12.333333   \n",
       "\n",
       "    Self_Monitoring_T0  Self_Monitoring_T1  \n",
       "0                 4.25                4.00  \n",
       "2                  NaN                 NaN  \n",
       "6                 4.50                4.25  \n",
       "7                 4.00                 NaN  \n",
       "12                5.00                3.00  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_intervention_final.info()\n",
    "df_intervention_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 763 entries, 1 to 3188\n",
      "Data columns (total 38 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   Age                                763 non-null    int64  \n",
      " 1   Sex                                763 non-null    int64  \n",
      " 2   MVPA_Frequency_T0                  750 non-null    float64\n",
      " 3   Leisure_Exercise_T0                747 non-null    float64\n",
      " 4   YAP_sedentary_general_T0           746 non-null    float64\n",
      " 5   Leisure_PA_T0                      743 non-null    float64\n",
      " 6   MVPA_Usual_Week_T0                 751 non-null    float64\n",
      " 7   Group_Final                        763 non-null    object \n",
      " 8   Weight_kg_T0                       763 non-null    int64  \n",
      " 9   Weight_kg_T1                       649 non-null    float64\n",
      " 10  Height_cm_T0                       763 non-null    int64  \n",
      " 11  Height_cm_T1                       649 non-null    float64\n",
      " 12  MVPA_Frequency_T1                  753 non-null    float64\n",
      " 13  MVPA_Usual_Week_T1                 750 non-null    float64\n",
      " 14  Leisure_Exercise_T1                750 non-null    float64\n",
      " 15  PE_hours_T0                        761 non-null    float64\n",
      " 16  PE_hours_T1                        755 non-null    float64\n",
      " 17  Extracurricular_Session_Coach_T0   749 non-null    float64\n",
      " 18  Extracurricular_Session_Coach_T1   750 non-null    float64\n",
      " 19  Extracurricular_Session_School_T0  733 non-null    float64\n",
      " 20  Extracurricular_Session_School_T1  727 non-null    float64\n",
      " 21  Leisure_PA_T1                      737 non-null    float64\n",
      " 22  YAP_sedentary_general_T1           719 non-null    float64\n",
      " 23  COVID_impact_T0                    737 non-null    float64\n",
      " 24  COVID_impact_T1                    722 non-null    float64\n",
      " 25  SixMW_T0                           763 non-null    int64  \n",
      " 26  SixMW_T1                           654 non-null    float64\n",
      " 27  SLJ_T0                             759 non-null    float64\n",
      " 28  SLJ_T1                             672 non-null    float64\n",
      " 29  HG_Right_T0                        593 non-null    float64\n",
      " 30  HG_Left_T0                         593 non-null    float64\n",
      " 31  HG_Right_T1                        665 non-null    float64\n",
      " 32  HG_Left_T1                         661 non-null    float64\n",
      " 33  MVPA_Improvement                   741 non-null    float64\n",
      " 34  Motivation_T0                      635 non-null    float64\n",
      " 35  Motivation_T1                      592 non-null    float64\n",
      " 36  Self_Monitoring_T0                 710 non-null    float64\n",
      " 37  Self_Monitoring_T1                 646 non-null    float64\n",
      "dtypes: float64(32), int64(5), object(1)\n",
      "memory usage: 232.5+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>MVPA_Frequency_T0</th>\n",
       "      <th>Leisure_Exercise_T0</th>\n",
       "      <th>YAP_sedentary_general_T0</th>\n",
       "      <th>Leisure_PA_T0</th>\n",
       "      <th>MVPA_Usual_Week_T0</th>\n",
       "      <th>Group_Final</th>\n",
       "      <th>Weight_kg_T0</th>\n",
       "      <th>Weight_kg_T1</th>\n",
       "      <th>...</th>\n",
       "      <th>SLJ_T1</th>\n",
       "      <th>HG_Right_T0</th>\n",
       "      <th>HG_Left_T0</th>\n",
       "      <th>HG_Right_T1</th>\n",
       "      <th>HG_Left_T1</th>\n",
       "      <th>MVPA_Improvement</th>\n",
       "      <th>Motivation_T0</th>\n",
       "      <th>Motivation_T1</th>\n",
       "      <th>Self_Monitoring_T0</th>\n",
       "      <th>Self_Monitoring_T1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>B</td>\n",
       "      <td>30</td>\n",
       "      <td>43.0</td>\n",
       "      <td>...</td>\n",
       "      <td>90.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>B</td>\n",
       "      <td>32</td>\n",
       "      <td>32.0</td>\n",
       "      <td>...</td>\n",
       "      <td>185.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.666667</td>\n",
       "      <td>14.833333</td>\n",
       "      <td>2.75</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>B</td>\n",
       "      <td>65</td>\n",
       "      <td>69.0</td>\n",
       "      <td>...</td>\n",
       "      <td>129.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.75</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>B</td>\n",
       "      <td>36</td>\n",
       "      <td>36.0</td>\n",
       "      <td>...</td>\n",
       "      <td>136.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>B</td>\n",
       "      <td>37</td>\n",
       "      <td>38.0</td>\n",
       "      <td>...</td>\n",
       "      <td>197.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Sex  MVPA_Frequency_T0  Leisure_Exercise_T0  \\\n",
       "1    11    2                6.0                  1.0   \n",
       "3    11    2                2.0                  2.0   \n",
       "4    11    2                1.0                  2.0   \n",
       "10   11    1                2.0                  3.0   \n",
       "11   11    1                3.0                  4.0   \n",
       "\n",
       "    YAP_sedentary_general_T0  Leisure_PA_T0  MVPA_Usual_Week_T0 Group_Final  \\\n",
       "1                        2.0            1.0                 6.0           B   \n",
       "3                        2.0            2.0                 2.0           B   \n",
       "4                        3.0            2.0                 1.0           B   \n",
       "10                       3.0            2.0                 2.0           B   \n",
       "11                       2.0            3.0                 2.0           B   \n",
       "\n",
       "    Weight_kg_T0  Weight_kg_T1  ...  SLJ_T1  HG_Right_T0  HG_Left_T0  \\\n",
       "1             30          43.0  ...    90.0         23.0        24.0   \n",
       "3             32          32.0  ...   185.0         22.0        23.0   \n",
       "4             65          69.0  ...   129.0         23.0        17.0   \n",
       "10            36          36.0  ...   136.0         14.0        10.0   \n",
       "11            37          38.0  ...   197.0         24.0        25.0   \n",
       "\n",
       "    HG_Right_T1  HG_Left_T1  MVPA_Improvement  Motivation_T0  Motivation_T1  \\\n",
       "1          11.0        12.0              -4.0      10.000000      11.500000   \n",
       "3          21.0        20.0               1.0      13.666667      14.833333   \n",
       "4          20.0        19.0               2.0      10.000000       2.500000   \n",
       "10         10.0        10.0               2.0      11.500000       9.000000   \n",
       "11         24.0        22.0               1.0       3.333333       9.500000   \n",
       "\n",
       "    Self_Monitoring_T0  Self_Monitoring_T1  \n",
       "1                 2.75                2.75  \n",
       "3                 2.75                4.00  \n",
       "4                 1.75                 NaN  \n",
       "10                3.50                3.75  \n",
       "11                4.25                4.00  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_control_final.info()\n",
    "df_control_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Export Final Datasets\n",
    "\n",
    "Export the cleaned datasets to separate CSV files for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Intervention group exported to: data/intervention_group_clean.csv\n",
      "   1007 participants, 38 variables\n",
      "\n",
      "✅ Control group exported to: data/control_group_clean.csv\n",
      "   763 participants, 38 variables\n",
      "\n",
      "======================================================================\n",
      "DATA PREPARATION COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "Next steps:\n",
      "  1. Use intervention_group_clean.csv for intervention analysis\n",
      "  2. Use control_group_clean.csv for control analysis\n",
      "  3. Compare outcomes between groups for effectiveness evaluation\n"
     ]
    }
   ],
   "source": [
    "# Export intervention group\n",
    "intervention_filename = 'data/intervention_group_clean.csv'\n",
    "df_intervention_final.to_csv(intervention_filename, index=False)\n",
    "print(f\"Intervention group exported to: {intervention_filename}\")\n",
    "print(f\"   {len(df_intervention_final)} participants, {df_intervention_final.shape[1]} variables\")\n",
    "\n",
    "# Export control group\n",
    "control_filename = 'data/control_group_clean.csv'\n",
    "df_control_final.to_csv(control_filename, index=False)\n",
    "print(f\"\\nControl group exported to: {control_filename}\")\n",
    "print(f\"   {len(df_control_final)} participants, {df_control_final.shape[1]} variables\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.13.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
